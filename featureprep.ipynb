{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is summary of data schema - \n",
    "![image](https://storage.googleapis.com/kaggle-media/competitions/home-credit/home_credit.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df = pd.read_csv('../input/application_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoder(dfname):\n",
    "    le = LabelEncoder()\n",
    "    j = 0\n",
    "    for column in dfname:\n",
    "        if dfname[column].dtype == 'object':\n",
    "            if len(list(dfname[column].unique())) <= 2:\n",
    "                le.fit(dfname[column])\n",
    "                dfname[column] = le.transform(dfname[column])\n",
    "                j += 1\n",
    "    print(str(j) + ' Columns encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Columns encoded\n"
     ]
    }
   ],
   "source": [
    "label_encoder(train_data_df)\n",
    "train_data_df = pd.get_dummies(train_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For each table counting no. of entries for each loan and averaging out all entries to create one row per loan\n",
    "1. Count the no. of entries in new table which has primary key SK_ID_PREV for each value of SK_ID_CURR which is the foreign key referring to a loan\n",
    "2. take rest of columns and take average of all entries\n",
    "3. append table identifier to prevent name clashes\n",
    "4. Join the table with main table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previous loan applications data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Columns encoded\n"
     ]
    }
   ],
   "source": [
    "prev_applications_df = pd.read_csv('../input/previous_application.csv')\n",
    "label_encoder(prev_applications_df)\n",
    "prev_applications_df = pd.get_dummies(prev_applications_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_apps_count = prev_applications_df[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "prev_applications_df['SK_ID_PREV'] = prev_applications_df['SK_ID_CURR'].map(previous_apps_count['SK_ID_PREV'])\n",
    "previous_apps_mean = prev_applications_df.groupby('SK_ID_CURR').mean()\n",
    "previous_apps_mean.columns = ['prev_apps' + col for col in previous_apps_mean.columns]\n",
    "train_data_df = train_data_df.merge(right=previous_apps_mean.reset_index(), how='left', on='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previous loan payments data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Columns encoded\n"
     ]
    }
   ],
   "source": [
    "installments_df = pd.read_csv('../input/installments_payments.csv')\n",
    "label_encoder(installments_df)\n",
    "installments_df = pd.get_dummies(installments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "installments_count = installments_df[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "installments_df['SK_ID_PREV'] = installments_df['SK_ID_CURR'].map(installments_count['SK_ID_PREV'])\n",
    "installments_mean = installments_df.groupby('SK_ID_CURR').mean()\n",
    "installments_mean.columns = ['installment_' + col for col in installments_mean.columns]\n",
    "train_data_df = train_data_df.merge(right=installments_mean.reset_index(), how='left', on='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly balance data of loans previously held"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Columns encoded\n"
     ]
    }
   ],
   "source": [
    "previous_loans_df = pd.read_csv('../input/POS_CASH_balance.csv')\n",
    "label_encoder(previous_loans_df)\n",
    "previous_loans_df = pd.get_dummies(previous_loans_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_loans_count = previous_loans_df[['SK_ID_CURR','SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "previous_loans_df['SK_ID_PREV'] = previous_loans_df['SK_ID_CURR'].map(previous_apps_count['SK_ID_PREV'])\n",
    "previous_loans_mean = previous_loans_df.groupby('SK_ID_CURR').mean()\n",
    "previous_loans_mean.columns = ['prev_loans_' + col for col in previous_loans_mean.columns]\n",
    "train_data_df = train_data_df.merge(right=previous_loans_mean.reset_index(), how='left', on='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit card balance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Columns encoded\n"
     ]
    }
   ],
   "source": [
    "credit_card_df = pd.read_csv('../input/credit_card_balance.csv')\n",
    "label_encoder(credit_card_df)\n",
    "credit_card_df = pd.get_dummies(credit_card_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_count = credit_card_df[['SK_ID_CURR','SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "credit_card_df['SK_ID_PREV'] = credit_card_df['SK_ID_CURR'].map(credit_card_count['SK_ID_PREV'])\n",
    "credit_card_mean = credit_card_df.groupby('SK_ID_CURR').mean()\n",
    "credit_card_mean.columns = ['card_'+ col for col in credit_card_mean.columns]\n",
    "train_data_df = train_data_df.merge(right=credit_card_mean.reset_index(), how='left',on='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applicant's credit bureau history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Columns encoded\n"
     ]
    }
   ],
   "source": [
    "bureau_history_df = pd.read_csv('../input/bureau.csv')\n",
    "label_encoder(bureau_history_df)\n",
    "bureau_history_df = pd.get_dummies(bureau_history_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_history_count =bureau_history_df[['SK_ID_CURR','SK_ID_BUREAU']].groupby('SK_ID_CURR').count()\n",
    "bureau_history_df['SK_ID_BUREAU'] = bureau_history_df['SK_ID_CURR'].map(bureau_history_count['SK_ID_BUREAU'])\n",
    "bureau_history_mean = bureau_history_df.groupby('SK_ID_CURR').mean()\n",
    "bureau_history_mean.columns = ['bureau_' + col for col in bureau_history_mean.columns]\n",
    "train_data_df = train_data_df.merge(right=bureau_history_mean.reset_index(), how='left', on='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputing Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data_df.drop('TARGET',axis=1)\n",
    "list_of_features = X.columns\n",
    "Y = train_data_df['TARGET']\n",
    "\n",
    "imputer = SimpleImputer()\n",
    "\n",
    "X = pd.DataFrame(imputer.fit_transform(X))\n",
    "X.columns = list_of_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.to_csv('../input/final_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('../input/final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
