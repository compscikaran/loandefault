{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_test,predictions,model):\n",
    "    print('\\033[1m' + model + '\\033[0m' + '\\n\\n')\n",
    "    print('\\033[1m' + 'Classification Report - ' + '\\033[0m')\n",
    "    print(classification_report(y_test,predictions))\n",
    "    print('\\033[1m' + 'ROC AUC Score - ' + '\\033[0m')\n",
    "    print(roc_auc_score(y_test,predictions))\n",
    "    print('\\033[1m' + 'Accuracy Score - ' + '\\033[0m')\n",
    "    print(accuracy_score(y_test,predictions))\n",
    "\n",
    "def dtree(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "    dt = DecisionTreeClassifier()\n",
    "    dt.fit(X_train,y_train)\n",
    "    predictions_dt = dt.predict(X_test)\n",
    "    print_metrics(y_test,predictions_dt,'Decision Tree')\n",
    "    \n",
    "def xboost(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "    boost = XGBClassifier(eval_metric='auc')\n",
    "    boost.fit(X_train,y_train)\n",
    "    predictions_boost = boost.predict(X_test)\n",
    "    print_metrics(y_test,predictions_boost,'XGBoost')\n",
    "    \n",
    "def rforrest(X,Y,n):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "    rfc = RandomForestClassifier(n_estimators=n,n_jobs=-1)\n",
    "    rfc.fit(X_train,y_train)\n",
    "    predictions_rfc = rfc.predict(X_test)\n",
    "    print_metrics(y_test,predictions_rfc,'Random Forrest')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_runner(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=18)\n",
    "    train_lgb = lgb.Dataset(data=X_train, label=y_train)\n",
    "    test_lgb = lgb.Dataset(data=X_test, label=y_test)\n",
    "    params = {'task': 'train', 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', \n",
    "          'learning_rate': 0.01, 'num_leaves': 48, 'verbose': 0 ,\n",
    "          'colsample_bytree':.8, 'subsample':.9, 'max_depth':7, 'reg_alpha':.1, 'reg_lambda':.1, \n",
    "          'min_split_gain':.01, 'min_child_weight':1}\n",
    "    model = lgb.train(params, train_lgb,500)\n",
    "    predictions_lgb = model.predict(X_test)\n",
    "    print('Light GBM')\n",
    "    print(roc_auc_score(y_test,predictions_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('../input/final_data.csv')\n",
    "Y = pd.read_csv('../input/final_target.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mXGBoost\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mClassification Report - \u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     84841\n",
      "           1       0.53      0.01      0.02      7413\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     92254\n",
      "   macro avg       0.73      0.50      0.49     92254\n",
      "weighted avg       0.89      0.92      0.88     92254\n",
      "\n",
      "\u001b[1mROC AUC Score - \u001b[0m\n",
      "0.5043619393179392\n",
      "\u001b[1mAccuracy Score - \u001b[0m\n",
      "0.9197433173629328\n"
     ]
    }
   ],
   "source": [
    "xboost(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Light GBM\n",
      "0.7729935820792314\n"
     ]
    }
   ],
   "source": [
    "lgbm_runner(X,Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
